# -*- coding: utf-8 -*-
"""ENGR421-HW6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1enEj4kS4TW3G_fKeecU6N5IBWPyuqApx
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import cvxopt as cvx
import scipy.spatial.distance as dt

#reading images and labels from .csv
images = np.asarray(pd.read_csv("/content/drive/MyDrive/hw06_images.csv", header = None))
labels = np.asarray(pd.read_csv("/content/drive/MyDrive/hw06_labels.csv", header = None))

#to silence the cvx solver
cvx.solvers.options['show_progress'] = False

#train and test split (first 1000 train, remaining 4000 test)
train_image = images[0:1000]
test_image = images[1000:len(images)]

train_labels = labels[0:1000]
test_labels = labels[1000:len(images)]

def gaussian_kernel(X1, X2, s):
    D = dt.cdist(X1, X2)
    K = np.exp(-D**2 / (2 * s**2))
    return(K)

#creates label 1 for the desired class and -1 for all other classes
def generate_one_versus_all_labels(class_no, labels):
  return np.asarray([1 if np.squeeze(labels[i]) == class_no else -1 for i in range(len(labels))])

#adapted from the code given in lab8
def get_class_score(X, y, C):
  s = 10
  K = gaussian_kernel(X, X, s)
  yyK = np.matmul(y[:,None], y[None,:]) * K

  epsilon = 1e-3

  N = len(X)

  P = cvx.matrix(yyK)
  q = cvx.matrix(-np.ones((N, 1)))
  G = cvx.matrix(np.vstack((-np.eye(N), np.eye(N))))
  h = cvx.matrix(np.vstack((np.zeros((N, 1)), C * np.ones((N, 1)))))
  A = cvx.matrix(1.0 * y[None,:])
  b = cvx.matrix(0.0)
                      
  # use cvxopt library to solve QP problems
  result = cvx.solvers.qp(P, q, G, h, A, b)
  alpha = np.reshape(result["x"], N)
  alpha[alpha < C * epsilon] = 0
  alpha[alpha > C * (1 - epsilon)] = C

  # find bias parameter
  support_indices, = np.where(alpha != 0)
  active_indices, = np.where(np.logical_and(alpha != 0, alpha < C))
  w0 = np.mean(y[active_indices] * (1 - np.matmul(yyK[np.ix_(active_indices, support_indices)], alpha[support_indices])))

  f_predicted = np.matmul(K, y[:,None] * alpha[:,None]) + w0
  

  return f_predicted, alpha, w0

#getting the scores and solved alpha and w0 parameters for classifier of each class (using C = 10)
score_1, alpha_1, w01= get_class_score(train_image,  generate_one_versus_all_labels(1,train_labels),10)
score_2, alpha_2, w02= get_class_score(train_image,  generate_one_versus_all_labels(2,train_labels),10)
score_3, alpha_3, w03= get_class_score(train_image,  generate_one_versus_all_labels(3,train_labels),10)
score_4, alpha_4, w04= get_class_score(train_image,  generate_one_versus_all_labels(4,train_labels),10)
score_5, alpha_5, w05= get_class_score(train_image,  generate_one_versus_all_labels(5,train_labels),10)

#stacking all scores
all_scores = np.hstack([score_1,score_2, score_3, score_4, score_5])

#setting the predicted labels by the max score 
y_predicted = np.vstack([np.squeeze(np.where(all_scores[i,:] == np.max(all_scores[i,:]))[0])+1 for i in range(len(all_scores))])

#the confusion matrix for the training set
confusion_matrix = pd.crosstab(np.squeeze(y_predicted), np.squeeze(train_labels), rownames = ['y_predicted'], colnames = ['y_train'])
print(confusion_matrix)

#for testing the generated models on test sets given the learned parameters
def test_model(kernel,y_train, alpha,w0):
  return np.matmul(kernel, y_train[:,None] * alpha[:,None]) + w0

s = 10
kernel = gaussian_kernel(test_image, train_image, s)
print(kernel.shape)

#stacking all learned parameters from earlierly generated model
alphas = np.vstack([alpha_1, alpha_2, alpha_3, alpha_4, alpha_5])
w0s = np.vstack([w01, w02, w03, w04, w05])

#generating scores using these parameters on the test set
all_scores = np.hstack([test_model(kernel, generate_one_versus_all_labels(i+1,train_labels), alphas[i][:], w0s[i]) for i in range(5)])

y_predicted = np.vstack([np.squeeze(np.where(all_scores[i,:] == np.max(all_scores[i,:]))[0])+1 for i in range(len(all_scores))])

#confusion matrix for the test set
confusion_matrix = pd.crosstab(np.squeeze(y_predicted), np.squeeze(test_labels), rownames = ['y_predicted'], colnames = ['y_train'])
print(confusion_matrix)

#to train a model with given C, and to calculate its accuracy on the test and training set 
def test_for_Cs(C):
  score_1, alpha_1, w01= get_class_score(train_image,  generate_one_versus_all_labels(1,train_labels),C)
  score_2, alpha_2, w02= get_class_score(train_image,  generate_one_versus_all_labels(2,train_labels),C)
  score_3, alpha_3, w03= get_class_score(train_image,  generate_one_versus_all_labels(3,train_labels),C)
  score_4, alpha_4, w04= get_class_score(train_image,  generate_one_versus_all_labels(4,train_labels),C)
  score_5, alpha_5, w05= get_class_score(train_image,  generate_one_versus_all_labels(5,train_labels),C)

  all_scores = np.hstack([score_1,score_2, score_3, score_4, score_5])
  y_predicted = np.vstack([np.squeeze(np.where(all_scores[i,:] == np.max(all_scores[i,:]))[0])+1 for i in range(len(all_scores))])
  confusion_matrix_train = pd.crosstab(np.squeeze(y_predicted), np.squeeze(train_labels), rownames = ['y_predicted'], colnames = ['y_train'])
  accuracy_train = np.trace(np.asarray(confusion_matrix_train))/np.sum(np.asarray(confusion_matrix_train))

  alphas = np.vstack([alpha_1, alpha_2, alpha_3, alpha_4, alpha_5])
  w0s = np.vstack([w01, w02, w03, w04, w05])

  all_scores = np.hstack([test_model(kernel, generate_one_versus_all_labels(i+1,train_labels), alphas[i][:], w0s[i]) for i in range(5)])
  y_predicted = np.vstack([np.squeeze(np.where(all_scores[i,:] == np.max(all_scores[i,:]))[0])+1 for i in range(len(all_scores))])
  confusion_matrix = pd.crosstab(np.squeeze(y_predicted), np.squeeze(test_labels), rownames = ['y_predicted'], colnames = ['y_train'])
  #print(confusion_matrix)
  
  return [np.trace(np.asarray(confusion_matrix))/np.sum(np.asarray(confusion_matrix)), accuracy_train]

Cs = [0.1, 1,10, 100, 1000]
accuracies = np.vstack([test_for_Cs(i) for i in Cs])

print(accuracies)
print(accuracies.shape)
print(np.transpose(accuracies)[0])
#accuracies 1st column for test accuracy, 2nd column for training accuracy

#plotting the accuracies by the C value on the test and training set
plt.figure(figsize = (10, 8))
plt.xscale('log')
plt.plot(Cs, np.transpose(accuracies)[0], "r.", markersize = 10)
plt.plot(Cs, np.transpose(accuracies)[0], "r", label = "test")
plt.plot(Cs, np.transpose(accuracies)[1], "b.", markersize = 10)
plt.plot(Cs, np.transpose(accuracies)[1], "b", label = "training")
plt.legend(loc = 'best')
plt.ylabel("Accuracies")
plt.xlabel("Regularization Parameter (C)")